---
title: "R Notebook"
output: html_notebook
---

```{r}
#install.packages("rtweet")
library(tidyverse)
library(rtweet)
library(janitor)
library(skimr)
```
#Maybe look at rtweet package depending how I get on with rest of work

#Question 1.
Load the code_clan_tweets.csv data. Find the number of rows, columns, and list all the variable names.
```{r}
tweets <- read_csv("code_clan_tweets.csv")
tweets <- clean_names(tweets)
nrow(tweets)
ncol(tweets)
names(tweets)
head(tweets)
```
#Question 2.
Find the total number of favourites (stored in favorite_count) that CodeClan tweets have got. Don’t add a tweet’s favorite_count to the total when the tweet was quoted (see the is_quote variable).
_filter out any tweets where is_quote = TRUE. sum favorite_count_
_There have been 7 tweets which were quotes_
_These remaining 227 tweets have been favorited a total of 425 times_

```{r}
tweets %>% 
  filter(is_quote == TRUE) %>% 
  count()

tweets %>% 
  filter(is_quote == FALSE) %>% 
  summarise(favorite_count = sum(favorite_count))
```
#Question 3.
Summarise the mean number of retweets (retweet_count), split by the type of platform that was used to tweet (source). Again, omit quoted tweets from the mean.
_filter as before, then group by source, then summarise mean retweets_
```{r}
tweets %>% 
  filter(is_quote == FALSE) %>% 
  group_by(source) %>% 
  summarise(mean_no_retweets_by_source = mean(retweet_count)) %>% 
  arrange(desc(mean_no_retweets_by_source))
```
#Question 4.
Count the total number of likes (i.e. total of favorite_count), split by media type, and arrange them from most likes to least. Assume that any tweets without a listed media type are of type “text”.
_Change NA in media type to text using coalesce_
_group by media type and count number_of_likes, arranged desc_
_Photos get more likes than text based tweets_
```{r}
#I did mean instead of sum originally
tweets %>%
  mutate(media_type = coalesce(media_type, "text")) %>% 
  group_by(media_type) %>% 
  summarise(number_of_likes = sum(favorite_count)) %>% 
  arrange(desc(number_of_likes))
```
#Question 5.
Find the mean number of characters that a CodeClan tweet contains. You can either find a way to count the text in the text variable, or use the variable display_text_width which contains a count. Checking both would be a good idea if possible to see if they match (but it’s not essential).
_using all tweets to calculate mean number of characters, no filters required_
_using basic summarise on displ_text_width mean = 149.4 characters_
_used nchar and str_length to check length of the string in text, this did not provide the same results as the display_text_width column_
_new result for average tweet length is 188.4 characters_
```{r}
#by using variable_display_text_width
tweets %>% 
  summarise(mean_characters_in_tweets = mean(display_text_width))
#finding length using str_length
tweets %>%
  select(tweet_id, text, display_text_width) %>% 
  mutate(characters_in_tweet = str_length(text))
#finding length using nchar and then doing summary statistics
tweets %>%
  select(tweet_id, text, display_text_width) %>% 
  mutate(characters_in_tweet = nchar(text)) %>% 
  summarise(mean_characters_in_tweets_from_text = mean(characters_in_tweet))
```
#Question 6.
The code_clan_info.csv data file contains status_url along with other info. Load this in, and join it to the code_clan_tweets tibble, so that you have a status_url for each tweet. Decide which variable to join the tibbles on.
_join tibbles on the tweet_id column_
_if all data is unique this should provide 27 + 15 variables (-1 for join variable) = 41_
```{r}
info <- read_csv("code_clan_info.csv")
info

full_data <- tweets %>% 
  full_join(info, by = c("tweet_id"))
tweets %>% 
  left_join(info, by = c("tweet_id"))


full_data
#check all rows have joined
15 + 27 - 1
```
#Question 7.
From your new joined data, create a new tibble codeclan_hashtags containing only tweet_id and hashtags, then convert hashtags into lowercase for analysis. Keep only those tweets with hashtags.
_select tweet_id and hashtags, then filter NOT is.na on hashtags, drops rows to 117, then mutate hashtags column using str_to_lower_
```{r}
code_clan_hashtags <- full_data %>% 
  select(tweet_id, hashtags) %>% 
  filter(!is.na(hashtags)) %>% 
  mutate(hashtags = str_to_lower(hashtags))


#codeclan answer
full_data %>% 
  select(tweet_id, hashtags) %>% 
  mutate(lower_hashtags = str_to_lower(hashtags)) %>% 
  select(-hashtags) %>% 
  drop_na(lower_hashtags)


code_clan_hashtags
```
#4 Extensions
#Question 8.
Some tweets have more than one hashtag, denoted by the c( symbols at the start of the string. Use the str_sub() and str_detect() functions and your codeclan_hashtags tibble from above to find all the cases in which the hashtag string begins with charactersc(.
_Use str_detect to find all cases with this, there are 49 in total_
```{r}
#Question 8

code_clan_hashtags %>%
  mutate(hashtags_detect = str_detect(hashtags, "c\\(")) %>% 
  filter(hashtags_detect == TRUE)

code_clan_hashtags %>%
  mutate(hashtags_detect = str_detect(hashtags, "^c\\(")) %>% 
  filter(hashtags_detect == TRUE)


#CodeClan answer
code_clan_hashtags %>%
  filter(str_detect(hashtags, "^c\\("))
```
#Question 9.
Use the str_detect() function to find all tweets with text that mentions “Edinburgh”, and count how many such tweets there are.
_as above, remembering to filter out case sensitivity and later trying by changing column to all lower case_
_There are 8 tweets with the hashtag edinburgh_
```{r}
code_clan_hashtags %>%
  mutate(hashtags_edinburgh = str_detect(hashtags, "(?i)edinburgh")) %>% 
  filter(hashtags_edinburgh == TRUE)

code_clan_hashtags %>% 
  mutate(hashtags_lower = str_to_lower(hashtags)) %>% 
  mutate(hashtags_detect = str_detect(hashtags_lower, "edinburgh")) %>% 
  filter(hashtags_detect == TRUE)
#my version but for the correct criteria
full_data %>% 
  mutate(text = str_to_lower(text)) %>% 
  mutate(text_lower = str_detect(text, "edinburgh")) %>% 
  filter(text_lower == TRUE)

#correct answer
full_data %>% 
  mutate(text_lower = str_to_lower(text)) %>% 
  filter(str_detect(text_lower, "edinburgh")) %>% 
  summarise(count = n())
```
#Question 10.
Use str_extract_all() with a regular expression to find out which Twitter users CodeClan have been tweeting.
_Find the usernames with the text, initial pull found the quantity of users tweeted_
_Used str_extract_all with unnest to main tibble format_
_used str_detect to check how often a user was tweeted, only 147 of 234 tweets contained this_
```{r}
#thought this would work but it only returns the amount of results
tweets %>% 
  select(text) %>% 
  mutate(user_tweeeted = str_extract_all(text, "@[A-z0-9_]+"))
#this works, needed the unnest function
tweets %>% 
  select(text) %>% 
  mutate(user_tweeeted = str_extract_all(text, "@[A-z0-9_]+")) %>% 
  unnest(cols = c(user_tweeeted)) %>% 
  group_by(user_tweeeted) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
#this shows the frequency at which someone is specifically tweeted
tweets %>% 
  select(text) %>% 
  mutate(was_a_user_tweeted = str_detect(text, "@[A-z0-9_]+")) %>% 
  filter(was_a_user_tweeted == TRUE)
```